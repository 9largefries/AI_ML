{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2 # \n",
    "## Студент: Девяткина Д.В. \n",
    "## Группа: М8О-304Б\n",
    "\n",
    "\n",
    "### Постановка задачи\n",
    "1. Требуется реализовать класс на выбранном языке программирования, который реализует один из алгоритмов машинного обучения. Обязательным является наличия в классе двух методов fit, predict. \n",
    "2. Необходимо проверить работу вашего алгоритма на ваших данных (на таблице и на текстовых данных), произведя необходимую подготовку данных. \n",
    "3. Также необходимо реализовать алгоритм полиномиальной регрессии, для предсказания значений в таблице. \n",
    "4. Сравнить результаты с стандартной реализацией sklearn, определить в чем сходство и различие ваших алгоритмов. \n",
    "5. Замерить время работы алгоритмов.\n",
    "\n",
    "### Алгоритм\n",
    "Наивный байесовский классификатор\n",
    " \n",
    "4 % 6 + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание алгоритма\n",
    "\n",
    "Наивный Байесовский классификатор основан на теореме Байеса и является \"наивным\", потому что мы делаем допущение о том, что признаки независимы.\n",
    "\n",
    "В своей работе я реализовала 2 модели байесовского классификатора. \n",
    "1. *Gaussian* (нормальное распределение). Модель данного типа используется в случае непрерывных признаков и предполагает, что значения признаков имеют нормальное распределение.\n",
    "Это распределение удобно использовать с численными данными, поэтому я его приложила к численному датасету.\n",
    "2. *Multinomial* (мультиномиальное распределение). Используется в случае дискретных признаков. Например, в задаче классификации текстов признаки могут показывать, сколько раз каждое слово встречается в данном тексте.\n",
    "Эта модель приложена к корпусу документов. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация Мультиномиальной модели\n",
    "\n",
    "Была использована формула:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных текстового датасета\n",
    "\n",
    "Выбранный [корпус](https://github.com/kavgan/OpinRank/blob/master/OpinRankDatasetWithJudgments.zip) документов - отзывы на отели в 3 городах: Лондон, Дубаи, Лас-Вегас\n",
    "\n",
    "*Предварительно разделяю на класс \"Дубаи\" и \"Лондон\".*\n",
    "\n",
    "Количество отзывов на Дубаи: 236\n",
    "\n",
    "Выбранно количество отзывов на Лондон: 250 (так как размер словаря после всей обработки при, например, 690 файлах, переваливает за 100к слов, и выходит MemoryError)\n",
    "\n",
    "Задача: Определение к какому классу (городу) относятся отзывы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм\n",
    "Вероятность считается по следующей формуле: \n",
    "\n",
    "![основная формула](https://cdn-images-1.medium.com/max/1000/1*4XdLoLXubDsN9Jix_OdJVA.gif)\n",
    "\n",
    "где pi(j) - вероятность документов класса j среди всех документов\n",
    "\n",
    "![т](https://cdn-images-1.medium.com/max/1000/1*QbeBoi9mCJPLKBG6YlW9Sg.gif)\n",
    "\n",
    "IDF (Inverse Document Frequency), однако в последствии я убрала её из расчета, так как время работы алгоритма с ней увеличилось в значительной степени. \n",
    "\n",
    "![лаплас](https://cdn-images-1.medium.com/max/1000/1*L0RGaXZGrsAxkkFoINabUw.png)\n",
    "\n",
    "Сглаживание Лапласа с малым параметром альфа и V - размер словаря.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем нужные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [oct, good, overall, service, just, came, back...\n",
       "1    [value, for, money, the, hotel, has, very, goo...\n",
       "2    [jun, excellent, and, near, the, airport, i, h...\n",
       "3    [nov, great, for, relaxing, stopovers, this, i...\n",
       "4    [oct, information, about, alhijaz, heritage, m...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаем датафрейм с названием отеля, текстом отзывов, городом (классом)\n",
    "dir1 = 'dubai/'\n",
    "dir3 = 'london/'\n",
    "files1 = os.listdir(dir1)\n",
    "files3 = os.listdir(dir3)\n",
    "files3 = files3[0:260]\n",
    "\n",
    "df = pd.DataFrame(columns = ['hotel', 'review'])\n",
    "\n",
    "towns = [files1, files3]\n",
    "dirr = [dir1, dir3]\n",
    "\n",
    "i, j = 0, 0\n",
    "for files in towns:\n",
    "    for file in files:\n",
    "        text = ''\n",
    "        hotel = open(dirr[j]+file, 'r')\n",
    "        for line in hotel: text += line\n",
    "        df.loc[i] = [file, text]\n",
    "        i += 1\n",
    "    j += 1\n",
    "\n",
    "town = []\n",
    "for hotel in df['hotel']:\n",
    "    if 'dubai' in hotel: town.append(0)\n",
    "    else: town.append(1)\n",
    "\n",
    "#получаем датафрейм со столбцами [отель, отзыв, город(0/1 или Дубаи/Лондон)]\n",
    "df['town'] = town\n",
    "\n",
    "#меняем все буквы на строчные\n",
    "df['review'] = df.review.map(lambda x: x.lower()) \n",
    "\n",
    "#удаляем все цифры\n",
    "df['review'] = df.review.str.replace('\\d', '')\n",
    "\n",
    "#удаляем пунктуацию\n",
    "df['review'] = df.review.str.replace('[^\\w\\s]', '')\n",
    "\n",
    "#токенизация\n",
    "df['review'] = df['review'].apply(nltk.word_tokenize) \n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер полученного словаря:  79569\n",
      "Разделено 496 документов на 297 обучающих и 199 тестовых\n"
     ]
    }
   ],
   "source": [
    "#стемминг \n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "df['review'] = df['review'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "\n",
    "# перевод списка слов обратно в строку\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join(x))\n",
    "df['review'].head()\n",
    "\n",
    "#сконвертируем набор текстов в матрицу токенов\n",
    "count_vect = CountVectorizer() \n",
    "counts = count_vect.fit_transform(df['review']).toarray()\n",
    "\n",
    "print('Размер полученного словаря: ', len(counts[0]))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(counts, df['town'].values, test_size = 0.4)\n",
    "print('Разделено {0} документов на {1} обучающих и {2} тестовых'.format(len(counts),len(x_train),len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "class NBMultinomial:\n",
    "    def __init__(self):\n",
    "        self.stat = {} #{класс: (количество докуменов с таким классом, количество слов в этом классе, массив вхождений слов в этом классе)}\n",
    "        self.words = 0 #количество слов в словаре \n",
    "        self.docs = 0 #количество документов в обучающей выборке\n",
    "        \n",
    "    def fit(self, counts, train):\n",
    "        #получим классы и количество каждого класса\n",
    "        classes, num_c = np.unique(train, return_counts=True)\n",
    "        self.words = len(counts[0])\n",
    "        self.docs = len(train)\n",
    "        self.stat = {classes[i]: (num_c[i], 0, np.array([0] * self.words)) for i in range(len(classes))}\n",
    "        #для каждого класса получим статистику\n",
    "        for i in range(self.docs):\n",
    "            stat_doc = self.stat[train[i]]\n",
    "            self.stat[train[i]] = (stat_doc[0], stat_doc[1] + sum(counts[i]), stat_doc[2] + counts[i]) \n",
    "\n",
    "    def predict(self, test):\n",
    "        predicted = []\n",
    "        for i in range(len(test)):\n",
    "            #выбор наибольшей вероятности и присваиваем соответствующий класс\n",
    "            best_c, best_p = None, -math.inf\n",
    "            for c in self.stat.keys():\n",
    "                #вероятность класса среди всех документов\n",
    "                P = math.log(self.stat[c][0] / self.docs)\n",
    "                for j in range(self.words):\n",
    "                    #чтобы не было делений на 0 проверка на нулевое количество вхождений слова\n",
    "                    if test[i][j] != 0:\n",
    "                        #Inverse Document Frequency (IDF) weight on each word\n",
    "                        #ЗАМЕЧАНИЕ: видимо из-за того, что используется сумма строки на каждой итерации\n",
    "                        #время работы опять возрасло и я выкинула это из формулы\n",
    "                        #idf = math.log(sum(test[i]) / test[i][j])\n",
    "                        #применяю сглаживание Лапласа\n",
    "                        #P += test[i][j] * math.log(idf * (self.stat[c][2][j] + alpha) / (self.stat[c][1] + self.words + 1))\n",
    "                        P += test[i][j] * math.log((self.stat[c][2][j] + alpha) / (self.stat[c][1] + self.words + 1))\n",
    "                if P > best_p: \n",
    "                    best_p, best_c = P, c\n",
    "            predicted.append(best_c)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильно предсказано: 1 из 199\n",
      "Точность: 0.9949748743718593\n",
      "Матрица ошибок:\n",
      " [[ 93   1]\n",
      " [  0 105]]\n",
      "Время работы собственного классификатора: 31.976750135421753 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "mnb = NBMultinomial()\n",
    "mnb.fit(x_train, y_train)\n",
    "y_pred = mnb.predict(x_test)\n",
    "\n",
    "print('Неправильно предсказано: {} из {}\\nТочность: {}'.format((y_test != y_pred).sum(), len(y_pred), accuracy_score(y_test, y_pred)))\n",
    "print('Матрица ошибок:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "finish = time.time()\n",
    "print('Время работы собственного классификатора: {} секунд'.format(finish-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получим те же результаты с помощью библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильно предсказано: 2 из 199\n",
      "Точность: 0.9899497487437185\n",
      "Матрица ошибок:\n",
      " [[ 92   2]\n",
      " [  0 105]]\n",
      "Время работы классификатора sklearn: 6.638439893722534 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "mnb_sk = MultinomialNB()\n",
    "mnb_sk.fit(x_train, y_train)\n",
    "y_pred2 = mnb_sk.predict(x_test)\n",
    "\n",
    "print('Неправильно предсказано: {} из {}\\nТочность: {}'.format((y_test != y_pred2).sum(), len(y_pred2), accuracy_score(y_test, y_pred2)))\n",
    "print('Матрица ошибок:\\n', confusion_matrix(y_test, y_pred2))\n",
    "\n",
    "finish = time.time()\n",
    "print('Время работы классификатора sklearn: {} секунд'.format(finish-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# НБК для категориального датасета\n",
    "\n",
    "*Выбранный [датасет](https://www.kaggle.com/nisargpatel/automobiles) - информация об автомобилях*\n",
    "\n",
    "Выглядит он так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized_losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>number_of_doors</th>\n",
       "      <th>body_style</th>\n",
       "      <th>drive_wheels</th>\n",
       "      <th>engine_location</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>fuel_system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling  normalized_losses         make fuel_type aspiration  \\\n",
       "0          3                168  alfa-romero       gas        std   \n",
       "1          3                168  alfa-romero       gas        std   \n",
       "2          1                168  alfa-romero       gas        std   \n",
       "3          2                164         audi       gas        std   \n",
       "4          2                164         audi       gas        std   \n",
       "\n",
       "  number_of_doors   body_style drive_wheels engine_location  wheel_base  \\\n",
       "0             two  convertible          rwd           front        88.6   \n",
       "1             two  convertible          rwd           front        88.6   \n",
       "2             two    hatchback          rwd           front        94.5   \n",
       "3            four        sedan          fwd           front        99.8   \n",
       "4            four        sedan          4wd           front        99.4   \n",
       "\n",
       "   ...    engine_size  fuel_system  bore  stroke compression_ratio horsepower  \\\n",
       "0  ...            130         mpfi  3.47    2.68               9.0        111   \n",
       "1  ...            130         mpfi  3.47    2.68               9.0        111   \n",
       "2  ...            152         mpfi  2.68    3.47               9.0        154   \n",
       "3  ...            109         mpfi  3.19    3.40              10.0        102   \n",
       "4  ...            136         mpfi  3.19    3.40               8.0        115   \n",
       "\n",
       "   peak_rpm city_mpg  highway_mpg  price  \n",
       "0      5000       21           27  13495  \n",
       "1      5000       21           27  16500  \n",
       "2      5000       19           26  16500  \n",
       "3      5500       24           30  13950  \n",
       "4      5500       18           22  17450  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация Гауссовской модели\n",
    "\n",
    "Необходимо найти наиболее вероятный класс объекта x, Байесовский классификатор использует оценку апостериорного максимума (Maximum a posteriori estimation) для определения наиболее вероятного класса. т.е. максимум вероятности P(y=c|x). Вероятность признаков предполагается распреденной нормально:\n",
    "\n",
    "![вер](https://i.postimg.cc/P5JCxW2g/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных категориального датасета\n",
    "\n",
    "Задача: предсказать количество дверей автомобиля в зависимости от типа кузова (кабриолет, хэтчбек, седан и т.д.), переднего/заднего/полного привода и есть ли турбонаддув. \n",
    "\n",
    "Как можно увидеть, они не занесены в численном виде, значит необходимо провести подготовку данных. Для этого, например, заменим в признаке видов привода fwd -> 0, rwd -> 1, 4wd -> 2. Проведем аналогичные операции с другими выбранными признаками.\n",
    "\n",
    "## Код программы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разделено 201 строк на 134 обучающих и 67 тестовых строк\n",
      "Неправильно предсказано: 6 из 67\n",
      "Точность: 91.04477611940298%\n",
      "Матрица ошибок:\n",
      " [[17  6]\n",
      " [ 0 44]]\n",
      "Время работы собственного классификатора: 0.03127145767211914 секунд\n"
     ]
    }
   ],
   "source": [
    "ad = pd.read_csv('Automobile.csv')\n",
    "\n",
    "#перевожу категориальные признаки в численные\n",
    "ad['numdoors_cleaned'] = np.where(ad['number_of_doors'] == 'two', 0, 1)\n",
    "ad['salon_cleaned'] = np.where(ad['body_style'] == 'convertible', 0, \n",
    "                               np.where(ad['body_style'] == 'hardtop',1, \n",
    "                                        np.where(ad['body_style'] == 'hatchback',2, \n",
    "                                                 np.where(ad['body_style'] == 'sedan',3, 4))))\n",
    "ad['wheels_cleaned'] = np.where(ad['drive_wheels'] == 'fwd', 0,\n",
    "                                np.where(ad['drive_wheels'] == 'rwd',1, 2))\n",
    "ad['aspiration_cleaned'] = np.where(ad['aspiration'] == 'std', 0, 1)\n",
    "\n",
    "used_features = [\n",
    "    'aspiration_cleaned',\n",
    "    'salon_cleaned',\n",
    "    'wheels_cleaned',\n",
    "    'numdoors_cleaned']\n",
    "\n",
    "#разбиение\n",
    "X_train, X_test = train_test_split(ad, test_size=0.33)\n",
    "print('Разделено {0} строк на {1} обучающих и {2} тестовых строк'.format(len(ad),len(X_train),len(X_test)))\n",
    "\n",
    "#функция поиска медианы\n",
    "def mean(nums):\n",
    "    mean = sum(nums) / float(len(nums))\n",
    "    return mean\n",
    "\n",
    "#функция поиска стандартного отклонения \n",
    "def stdev(nums):\n",
    "    variance = sum([pow(x - mean(nums), 2) for x in nums])/float(len(nums) - 1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "#функция вероятности нормального распределения\n",
    "def calcGauss(x, m, d):\n",
    "    exponent = math.exp( -(math.pow(x - m, 2) / (2 * math.pow(d, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * d)) * exponent\n",
    "\n",
    "#функция для предсказания класса для одного элемента(вектора) обучающей выборки\n",
    "def get_predict(stat, test_vec):\n",
    "    #вероятность каждого класса\n",
    "    probabilities = {}\n",
    "    for classVal, classStat in stat.items():\n",
    "        probabilities[classVal] = 1\n",
    "        for i in range(len(classStat)):\n",
    "            mean, stdev = classStat[i]\n",
    "            x = test_vec[i]\n",
    "            probabilities[classVal] *= calcGauss(x, mean, stdev)\n",
    "    \n",
    "    #выбор наибольшей вероятности и присваиваем соответствующий класс\n",
    "    best_c, best_p = None, -1\n",
    "    for classVal, probability in probabilities.items():\n",
    "        if best_c is None or probability > best_p:\n",
    "            best_p = probability\n",
    "            best_c = classVal\n",
    "    return best_c\n",
    "\n",
    "class NBClassifier():\n",
    "    def __init__(self):\n",
    "        self.stat = dict()\n",
    "    \n",
    "    def fit(self, X_train):\n",
    "        ln = len(X_train)\n",
    "        #разделение по классам данных\n",
    "        separated = {}\n",
    "        for i in range(ln):\n",
    "            vector = X_train[i]\n",
    "            if (vector[-1] not in separated):\n",
    "                separated[vector[-1]] = []\n",
    "            separated[vector[-1]].append(vector)\n",
    "            \n",
    "        #медиана и стандартное отклонение для каждого параметра внутри каждого класса\n",
    "        for classVal, instances in separated.items():\n",
    "            m_d = [(mean(col), stdev(col)) for col in zip(*instances)]\n",
    "            del m_d[-1]\n",
    "            self.stat[classVal] = m_d\n",
    "    \n",
    "    def predict(self, test):\n",
    "        predictions = []\n",
    "        for i in range(len(test)):\n",
    "            res = get_predict(self.stat, test[i])\n",
    "            predictions.append(res)\n",
    "        return predictions\n",
    "    \n",
    "start = time.time() \n",
    "\n",
    "nbc = NBClassifier()\n",
    "nbc.fit(X_train[used_features].values)\n",
    "\n",
    "test = X_test[used_features].values\n",
    "y_pred = nbc.predict(test)\n",
    "print('Неправильно предсказано: {} из {}\\nТочность: {}%'.format((X_test[\"numdoors_cleaned\"] != y_pred).sum(), len(y_pred), 100*(1-(X_test[\"numdoors_cleaned\"] != y_pred).sum()/len(y_pred))))     \n",
    "print('Матрица ошибок:\\n', confusion_matrix(X_test[\"numdoors_cleaned\"], y_pred))\n",
    "\n",
    "finish = time.time()\n",
    "print('Время работы собственного классификатора: {} секунд'.format(finish-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получим те же результаты с помощью библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильно предсказано: 6 из 67\n",
      "Точность: 91.04477611940298%\n",
      "Матрица ошибок:\n",
      " [[17  6]\n",
      " [ 0 44]]\n",
      "Время работы классификатора sklearn: 0.015604972839355469 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gnb = GaussianNB()\n",
    "used_features = [\n",
    "    'aspiration_cleaned',\n",
    "    'salon_cleaned',\n",
    "    'wheels_cleaned']\n",
    "\n",
    "gnb.fit(X_train[used_features].values,\n",
    "       X_train['numdoors_cleaned'])\n",
    "y_pred = gnb.predict(X_test[used_features])\n",
    "\n",
    "print('Неправильно предсказано: {} из {}\\nТочность: {}%'.format((X_test[\"numdoors_cleaned\"] != y_pred).sum(), len(y_pred), 100*(1-(X_test[\"numdoors_cleaned\"] != y_pred).sum()/len(y_pred))))     \n",
    "print('Матрица ошибок:\\n', confusion_matrix(X_test[\"numdoors_cleaned\"], y_pred))\n",
    "\n",
    "finish = time.time()\n",
    "print('Время работы классификатора sklearn: {} секунд'.format(finish-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем предсказать количество дверей, но теперь в зависимости от типа кузова (кабриолет, хэтчбек, седан и т.д.), размера двигателя и количества лошадиных сил."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильно предсказано: 6 из 67\n",
      "Точность: 91.04477611940298%\n",
      "Матрица ошибок:\n",
      " [[20  3]\n",
      " [ 3 41]]\n",
      "Время работы собственного классификатора: 0.03121352195739746 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "used_features = [\n",
    "    'horsepower',\n",
    "    'engine_size',\n",
    "    'salon_cleaned',\n",
    "    'numdoors_cleaned']\n",
    "nbc = NBClassifier()\n",
    "nbc.fit(X_train[used_features].values)\n",
    "\n",
    "test = X_test[used_features].values\n",
    "y_pred = nbc.predict(test)\n",
    "print('Неправильно предсказано: {} из {}\\nТочность: {}%'.format((X_test[\"numdoors_cleaned\"] != y_pred).sum(), len(y_pred), 100*(1-(X_test[\"numdoors_cleaned\"] != y_pred).sum()/len(y_pred))))     \n",
    "print('Матрица ошибок:\\n', confusion_matrix(X_test[\"numdoors_cleaned\"], y_pred))\n",
    "\n",
    "finish = time.time()\n",
    "print('Время работы собственного классификатора: {} секунд'.format(finish-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С помощью библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильно предсказано: 6 из 67\n",
      "Точность: 91.04477611940298%\n",
      "Матрица ошибок:\n",
      " [[20  3]\n",
      " [ 3 41]]\n",
      "Время работы классификатора sklearn: 0.015627145767211914 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gnb = GaussianNB()\n",
    "used_features = [\n",
    "    'horsepower',\n",
    "    'engine_size',\n",
    "    'salon_cleaned']\n",
    "\n",
    "gnb.fit(X_train[used_features].values,\n",
    "       X_train['numdoors_cleaned'])\n",
    "y_pred = gnb.predict(X_test[used_features])\n",
    "\n",
    "print('Неправильно предсказано: {} из {}\\nТочность: {}%'.format((X_test[\"numdoors_cleaned\"] != y_pred).sum(), len(y_pred), 100*(1-(X_test[\"numdoors_cleaned\"] != y_pred).sum()/len(y_pred))))     \n",
    "print('Матрица ошибок:\\n', confusion_matrix(X_test[\"numdoors_cleaned\"], y_pred))\n",
    "\n",
    "finish = time.time()\n",
    "print('Время работы классификатора sklearn: {} секунд'.format(finish-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с мультиномиальной моделью очень помогает скорректировать работу алгоритма сглаживание Лапласа, одна применение IDF параметра значительно повышает сложность и, соответственно, время работы алгоритма.\n",
    "Можно было воспользоваться td idf методом из библиотеки,что я и попробовала, однако, опять таки, не смогла дождаться когда программа закончит обработку. \n",
    "\n",
    "Так же из-за ограничений по памяти и не совсем хорошей работы стеммера, возникли сложности с увеличением количества файлов. \n",
    "\n",
    "Время выполнения алгоритма моей реализации и библиотечной отличается во много раз, однако точность одинакова. \n",
    "\n",
    "Гауссовский наивный байес занял у меня намного больше времен, так как требует выполнения бОльшего количества операций. Мы предполагаем, что признаки возникают независимо (не всегда правда в реальной жизни) и, что признаки возникают с нормальным распределением, что тоже не соотвествует действительности. Однако результаты при этом оказываются с довольно хорошей точностью. \n",
    "\n",
    "Время работы моего Байеса и библиотечного различаются уже меньше, чем мультиномиальный. \n",
    "\n",
    "Из проделанной работы можно судить об простоте и быстроте работы НБА, тем не менее работающего с большой точностью."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
